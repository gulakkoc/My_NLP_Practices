{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckFgXU36QC7I"
   },
   "source": [
    "## Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gwt-asmVfWy1"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVI3B3kcQC7L",
    "outputId": "8659c293-6aaf-4d9b-fc62-9ac09a21e8ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gulfa\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: contractions in c:\\users\\gulfa\\anaconda3\\lib\\site-packages (0.0.18)\n",
      "Requirement already satisfied: regex in c:\\users\\gulfa\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\gulfa\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\gulfa\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gulfa\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "# natural language toolkit\n",
    "!pip install nltk contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKnwZuyRQC7N"
   },
   "source": [
    "🔑    :     https://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "stqZ0iNlQC7N"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIVZNeB3QC7O"
   },
   "source": [
    "### Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3JPgI4coQC7O"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrlwxkdFQC7P"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "njmgcSE9QC7P"
   },
   "outputs": [],
   "source": [
    "sample_text= \"\"\"This is pretty cool. A good quality candy might cost $3.88 in New York. \n",
    "                But I don't think we buy it. Mr.Biden said $1,000,000. 2 cars.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pHpS0QoqQC7Q"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, wordpunct_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwtgntGxQC7Q"
   },
   "source": [
    "#### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASCpxs_WQQHn",
    "outputId": "282ef921-6ece-435b-a997-47ab161da07e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gulfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# To use tokenziers\n",
    "print(nltk.download('punkt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Brw2U9CXQC7Q",
    "outputId": "f2ecee97-2494-4860-9b7d-1b05c5208df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is pretty cool.', 'a good quality candy might cost $3.88 in new york.', \"but i don't think we buy it.\", 'mr.biden said $1,000,000.', '2 cars.']\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = sent_tokenize(sample_text.lower()) # Sensitive to punctuation '.' vs ','\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zLpDtxgQC7R"
   },
   "source": [
    "#### WordPunct Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nks9ILs4QC7R",
    "outputId": "57aad28c-064d-47b2-c071-a2a9ad05269b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'pretty', 'cool', '.', 'a', 'good', 'quality', 'candy', 'might', 'cost', '$', '3', '.', '88', 'in', 'new', 'york', '.', 'but', 'i', 'don', \"'\", 't', 'think', 'we', 'buy', 'it', '.', 'mr', '.', 'biden', 'said', '$', '1', ',', '000', ',', '000', '.', '2', 'cars', '.']\n"
     ]
    }
   ],
   "source": [
    "wordpunc_tokens = wordpunct_tokenize(sample_text.lower()) # regular-expression based tokenizer, which splits text on whitespace and punctuation\n",
    "print(wordpunc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE3Vs9oTQC7R"
   },
   "source": [
    "#### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjJ95R43QC7R",
    "outputId": "af040cbf-4317-4607-a091-680964c7eaf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'pretty', 'cool', '.', 'a', 'good', 'quality', 'candy', 'might', 'cost', '$', '3.88', 'in', 'new', 'york', '.', 'but', 'i', 'do', \"n't\", 'think', 'we', 'buy', 'it', '.', 'mr.biden', 'said', '$', '1,000,000', '.', '2', 'cars', '.']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = word_tokenize(sample_text.lower())\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plKtrYtIQC7S"
   },
   "source": [
    "## Removing Punctuation and Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOSGvA72QC7S",
    "outputId": "46d56e7f-792f-4baa-a438-55e31302610e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'pretty', 'cool', 'a', 'good', 'quality', 'candy', 'might', 'cost', 'in', 'new', 'york', 'but', 'i', 'do', 'think', 'we', 'buy', 'it', 'said', 'cars']\n"
     ]
    }
   ],
   "source": [
    "tokens_without_punc = [w for w in word_tokens if w.isalpha()] # .isalnum() for number and object # we are losing mr.biden\n",
    "print(tokens_without_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqACGNxcQC7S"
   },
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J62SbXXRQC7S",
    "outputId": "9516f2bd-5f53-4db2-dcbf-ff3837e0b889"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gulfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "veA2ccj4QC7T"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg0P97lTQC7T",
    "outputId": "007fe930-75eb-4dd2-e89e-0220825896e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "len stop_words : 179\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "print(stop_words)\n",
    "print('len stop_words :', len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNNf1NVCQC7T",
    "outputId": "29cf36db-7431-426a-f7da-bc3bdf5507aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len new_stop_words : 141\n"
     ]
    }
   ],
   "source": [
    "words_to_exclude_from_stopwords = ['not', \"n't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \"don't\", 'hadn', \n",
    "                                   \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", \n",
    "                                   'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \n",
    "                                   \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "new_stopwords = [w for w in stop_words if w not in words_to_exclude_from_stopwords]\n",
    "print('len new_stop_words :', len(new_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DEv2JPfQC7U",
    "outputId": "36390a65-a0d6-49f3-998e-dbe50d84fa8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'pretty', 'cool', 'a', 'good', 'quality', 'candy', 'might', 'cost', 'in', 'new', 'york', 'but', 'i', 'do', 'think', 'we', 'buy', 'it', 'said', 'cars']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_without_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdiRp-6nQC7U",
    "outputId": "4656fd35-af0d-4387-f1be-ccac8fc1ad0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'cool', 'good', 'quality', 'candy', 'might', 'cost', 'new', 'york', 'think', 'buy', 'said', 'cars']\n"
     ]
    }
   ],
   "source": [
    "token_without_sw = [t for t in tokens_without_punc if t not in stop_words] # new_stopwords\n",
    "print(token_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoKQ-SVtQC7U"
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LGNumQbXQC7U"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4l4HUxCQC7U",
    "outputId": "41cbe1d5-03cd-483b-86cd-9a70184b5654"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gulfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "VWhaNmCVQC7V",
    "outputId": "3c2886ae-eac7-43fa-d27b-b77ad65028af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'driving'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'driver'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'drive'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"driving\")\n",
    "WordNetLemmatizer().lemmatize(\"driver\")\n",
    "WordNetLemmatizer().lemmatize(\"drives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ARIUDYl5QC7V"
   },
   "outputs": [],
   "source": [
    "lem = [WordNetLemmatizer().lemmatize(t) for t in token_without_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNdV9h47QC7V",
    "outputId": "0dd6d6d1-61ba-41e3-8fa2-cf100a462435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'cool', 'good', 'quality', 'candy', 'might', 'cost', 'new', 'york', 'think', 'buy', 'said', 'cars']\n",
      "['pretty', 'cool', 'good', 'quality', 'candy', 'might', 'cost', 'new', 'york', 'think', 'buy', 'said', 'car']\n"
     ]
    }
   ],
   "source": [
    "print(token_without_sw)\n",
    "print(lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bgiG6R2QC7V"
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UcXozBsEQC7V"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "27HrHpbzQC7V",
    "outputId": "c5116a64-5932-4aaf-b00f-d59a4d2698b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drive'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'driver'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'drive'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem(\"driving\")\n",
    "PorterStemmer().stem(\"driver\")\n",
    "PorterStemmer().stem(\"drives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2pwsWQW-QC7V"
   },
   "outputs": [],
   "source": [
    "stem = [PorterStemmer().stem(t) for t in token_without_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A40zGBvEQC7W",
    "outputId": "20ad626b-8241-495e-f8e4-071c59539f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o norm : ['pretty', 'cool', 'good', 'quality', 'candy', 'might', 'cost', 'new', 'york', 'think', 'buy', 'said', 'cars']\n",
      "stem     : ['pretti', 'cool', 'good', 'qualiti', 'candi', 'might', 'cost', 'new', 'york', 'think', 'buy', 'said', 'car']\n",
      "lemma    : ['pretty', 'cool', 'good', 'quality', 'candy', 'might', 'cost', 'new', 'york', 'think', 'buy', 'said', 'car']\n"
     ]
    }
   ],
   "source": [
    "print('w/o norm :', token_without_sw)\n",
    "print('stem     :', stem)\n",
    "print('lemma    :', lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY3VjHdeQC7W"
   },
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4fG6UucjQC7W",
    "outputId": "4fed74e0-803f-45de-de61-d1d2656eaeac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pretty cool good quality candy might cost new york think buy said car'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-7LnA8vQC7W"
   },
   "source": [
    "### Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3P2YfqIBQC7W",
    "outputId": "12799ed3-5e5d-432a-9e35-7f3b634724db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'will', 'go', 'there', 'i', \"'ve\", 'got', 'a', 'book']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text  = word_tokenize(contractions.fix(\"I'll go there I've got a book\".lower()))\n",
    "my_text\n",
    "#[w for w in my_text if w.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Nqhpu1ZqjNG"
   },
   "source": [
    "### Part of Speech Tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDQZCmChrXyO",
    "outputId": "a7cac0e7-d094-46a2-e015-d1794a4bf271"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gulfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2aLbZVnHqpwr"
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ha_24Xn4qvhq"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Steven Paul Jobs was an American business magnate, industrial designer, investor, and media proprietor. \n",
    "He was the chairman, chief executive officer (CEO), and co-founder of Apple Inc.; the chairman and majority shareholder of Pixar; \n",
    "a member of The Walt Disney Company's board of directors following its acquisition of Pixar; and the founder, chairman, and CEO of NeXT.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCR_drlTrJM2",
    "outputId": "39d8c956-b1ad-4cb7-b098-7caf36e59d03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Steven', 'NNP'),\n",
       " ('Paul', 'NNP'),\n",
       " ('Jobs', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('American', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " ('magnate', 'NN'),\n",
       " (',', ','),\n",
       " ('industrial', 'JJ'),\n",
       " ('designer', 'NN'),\n",
       " (',', ','),\n",
       " ('investor', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('media', 'NNS'),\n",
       " ('proprietor', 'NN'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('chairman', 'NN'),\n",
       " (',', ','),\n",
       " ('chief', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('officer', 'NN'),\n",
       " ('(', '('),\n",
       " ('CEO', 'NNP'),\n",
       " (')', ')'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('co-founder', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Apple', 'NNP'),\n",
       " ('Inc.', 'NNP'),\n",
       " (';', ':'),\n",
       " ('the', 'DT'),\n",
       " ('chairman', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('majority', 'NN'),\n",
       " ('shareholder', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Pixar', 'NNP'),\n",
       " (';', ':'),\n",
       " ('a', 'DT'),\n",
       " ('member', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('The', 'DT'),\n",
       " ('Walt', 'NNP'),\n",
       " ('Disney', 'NNP'),\n",
       " ('Company', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('board', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('directors', 'NNS'),\n",
       " ('following', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('acquisition', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Pixar', 'NNP'),\n",
       " (';', ':'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('founder', 'NN'),\n",
       " (',', ','),\n",
       " ('chairman', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('CEO', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('NeXT', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "pos = pos_tag(tokens)\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko_b0xHlqXk0"
   },
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPLpyNNetTxA",
    "outputId": "0b5938ba-42e3-4fbf-d40e-2aea01a65c5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\gulfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\gulfa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0JY5oaVPqc-9"
   },
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "jZ6qnCuwtMkq",
    "outputId": "c8c331d9-3a72-40aa-b048-381fa25b8a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n",
      "PERSON Steven\n",
      "PERSON Paul Jobs\n",
      "GPE American\n",
      "ORGANIZATION CEO\n",
      "ORGANIZATION Apple Inc.\n",
      "GPE Pixar\n",
      "ORGANIZATION Walt Disney Company\n",
      "GPE Pixar\n",
      "ORGANIZATION CEO\n",
      "ORGANIZATION NeXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Steven Paul Jobs was an American business magnate, industrial designer, investor, and media proprietor. \\nHe was the chairman, chief executive officer (CEO), and co-founder of Apple Inc.; the chairman and majority shareholder of Pixar; \\na member of The Walt Disney Company's board of directors following its acquisition of Pixar; and the founder, chairman, and CEO of NeXT.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import os\n",
    "if os.environ.get('DISPLAY','') == '':\n",
    "    print('no display found. Using non-interactive Agg backend')\n",
    "    mpl.use('Agg')\n",
    "\n",
    "for chunk in nltk.ne_chunk(pos):\n",
    "      if hasattr(chunk, 'label'):\n",
    "        print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fhd7AxIvQC7X"
   },
   "source": [
    "## Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6OrzWV8nIdZ",
    "outputId": "dc47ddc5-d2a6-4184-8a28-947ecabea3b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"n't\", 'want', 'fly', 'company', '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['I', 'want', 'fly', 'company']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### !!!!!!!!!!\n",
    "a = \"I don't want to fly with your company.\" # vs \n",
    "[token for token in word_tokenize(a) if token not in stop_words] \n",
    "b = \"I do not want to fly with your company\" \n",
    "[token for token in word_tokenize(b) if token not in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kQcS0m0_mdTt",
    "outputId": "b0275e02-381f-406a-9c8e-af2bcfa4eede"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I dont want to fly with your company.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I don't want to fly with your company.\".replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SBIpHb9WQC7X"
   },
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    \n",
    "    #1. Contractions Expension & Tokenize\n",
    "    #text_tokens = word_tokenize(contractions.fix(data.lower())) \n",
    "    text_tokens = word_tokenize(data.replace(\"'\", '').lower())\n",
    "    \n",
    "    #2. Remove Puncs\n",
    "    tokens_without_punc = [w for w in text_tokens if w.isalpha()]\n",
    "    \n",
    "    #3. Removing Stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    \n",
    "    #4. lemma\n",
    "    text_cleaned = [WordNetLemmatizer().lemmatize(t) for t in tokens_without_sw]\n",
    "    \n",
    "    #joining\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fadu17EQC7X"
   },
   "source": [
    "## CountVectorization and TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e18FSxq4TuQJ"
   },
   "source": [
    "#### Data\n",
    "🔑 Source: https://www.kaggle.com/crowdflower/twitter-airline-sentiment?select=Tweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sv7bi6bHQvDe",
    "outputId": "d163f05c-a071-40ba-f0de-9dcebfe9096f"
   },
   "outputs": [],
   "source": [
    "# For Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "eqImA_4OQC7X"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "#df = pd.read_csv(\"airline_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "0nQnCr5TQC7Y",
    "outputId": "81e7e1a5-01a8-493e-deca-35a9cb5bd863"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location  \\\n",
       "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOtx_XuLQC7Y",
    "outputId": "de008c9d-5506-4bef-e853-6376d36f31ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "2fw_lCtJQC7Y",
    "outputId": "6dc05b0d-3fb4-4acf-eb21-57b08b873fa8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9943</th>\n",
       "      <td>positive</td>\n",
       "      <td>@USAirways Ann Marie at LGA is the best ticket agent ever! #excellentcustomerservice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united your agents forced me to check a carry on bag. When I received my bag I found your crew had stolen from me. U lost my business!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica  - Is Flight 713 from Love Field to SFO definitely Cancelled Flightled for Monday, February 23?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>negative</td>\n",
       "      <td>@USAirways That's clever. Its clear you need more agents. 94 min hold and counting. Flex workforces are highly possible in 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir approaching three hours sitting in the plane on the ground at DFW on #AmericanAirlines flight 3056 - Oscar performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>neutral</td>\n",
       "      <td>YASSSSS. Da Fuccc- RT @JetBlue: Our fleet's on fleek. http://t.co/oAJ5mnuchA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica thank you for the easy itinerary shift for impending weather. Quick, painless &amp;amp; free.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>positive</td>\n",
       "      <td>@JetBlue Love you guys😍😍😍 http://t.co/3X9NRUOvtS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13128</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you keep returning my call and hanging up when I answer? Help reFlight Booking Problems a flight!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13196</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir back in UK now no thanks to your staff that wouldn't me or the other passengers stranded. Just laughed at us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14548</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir I hope you like the photo :) http://t.co/p7fSLuxEGW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>positive</td>\n",
       "      <td>@JetBlue I'm all set. About to fly. Not bad for a first date with a giant metal bird machine. She even brought snacks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir I took the day off from work and drove 9 hours round trip to rescue my daughter and 3 other students from LaGuardia. Thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir Finally got through after 3 hours and all set. Thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12881</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir @USAirways day has come where I was suppose to get my money back from you but my bank hasn't received anything but after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11059</th>\n",
       "      <td>negative</td>\n",
       "      <td>@UsAirways  your person taking tickets is rude and now we are delayed 4-50 minutes because you overfilled fuel on the plane #500.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5613</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir  when is the next flight with free cocktails ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13188</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir I've been trying to reach your customer service for TWO days. I have received zero response. Never traveling AA again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>positive</td>\n",
       "      <td>@SouthwestAir Your crew on 3138 is doing a great job of keeping everyone informed during the delays #givethemraises</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  \\\n",
       "9943   positive   \n",
       "2747   negative   \n",
       "5834    neutral   \n",
       "154     neutral   \n",
       "10401  negative   \n",
       "14033  negative   \n",
       "7004    neutral   \n",
       "252    positive   \n",
       "7305   positive   \n",
       "13128  negative   \n",
       "13196  negative   \n",
       "14548  positive   \n",
       "8572   positive   \n",
       "12821  negative   \n",
       "6397   negative   \n",
       "12881  negative   \n",
       "11059  negative   \n",
       "5613    neutral   \n",
       "13188  negative   \n",
       "4629   positive   \n",
       "\n",
       "                                                                                                                                            text  \n",
       "9943                                                        @USAirways Ann Marie at LGA is the best ticket agent ever! #excellentcustomerservice  \n",
       "2747     @united your agents forced me to check a carry on bag. When I received my bag I found your crew had stolen from me. U lost my business!  \n",
       "5834                                                                                                                          @SouthwestAir sent  \n",
       "154                               @VirginAmerica  - Is Flight 713 from Love Field to SFO definitely Cancelled Flightled for Monday, February 23?  \n",
       "10401            @USAirways That's clever. Its clear you need more agents. 94 min hold and counting. Flex workforces are highly possible in 2015  \n",
       "14033        @AmericanAir approaching three hours sitting in the plane on the ground at DFW on #AmericanAirlines flight 3056 - Oscar performance  \n",
       "7004                                                                YASSSSS. Da Fuccc- RT @JetBlue: Our fleet's on fleek. http://t.co/oAJ5mnuchA  \n",
       "252                                     @VirginAmerica thank you for the easy itinerary shift for impending weather. Quick, painless &amp; free.  \n",
       "7305                                                                                            @JetBlue Love you guys😍😍😍 http://t.co/3X9NRUOvtS  \n",
       "13128                             @AmericanAir you keep returning my call and hanging up when I answer? Help reFlight Booking Problems a flight!  \n",
       "13196                  @AmericanAir back in UK now no thanks to your staff that wouldn't me or the other passengers stranded. Just laughed at us  \n",
       "14548                                                                           @AmericanAir I hope you like the photo :) http://t.co/p7fSLuxEGW  \n",
       "8572                      @JetBlue I'm all set. About to fly. Not bad for a first date with a giant metal bird machine. She even brought snacks.  \n",
       "12821  @AmericanAir I took the day off from work and drove 9 hours round trip to rescue my daughter and 3 other students from LaGuardia. Thanks!  \n",
       "6397                                                                        @SouthwestAir Finally got through after 3 hours and all set. Thanks.  \n",
       "12881      @AmericanAir @USAirways day has come where I was suppose to get my money back from you but my bank hasn't received anything but after  \n",
       "11059          @UsAirways  your person taking tickets is rude and now we are delayed 4-50 minutes because you overfilled fuel on the plane #500.  \n",
       "5613                                                                                @SouthwestAir  when is the next flight with free cocktails ?  \n",
       "13188        @AmericanAir I've been trying to reach your customer service for TWO days. I have received zero response. Never traveling AA again.  \n",
       "4629                         @SouthwestAir Your crew on 3138 is doing a great job of keeping everyone informed during the delays #givethemraises  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['airline_sentiment','text']]\n",
    "df.rename(columns={'airline_sentiment':'sentiment'}, inplace=True)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Y-jRQzliQC7Z"
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "zwZbgya9QC7Z",
    "outputId": "c0764eff-9c42-4398-bc64-5564dd1772d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>virginamerica plus youve added commercial experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>virginamerica didnt today must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>virginamerica really aggressive blast obnoxious entertainment guest face amp little recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0   neutral   \n",
       "1  positive   \n",
       "2   neutral   \n",
       "3  negative   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "                                                                                     clean_text  \n",
       "0                                                                   virginamerica dhepburn said  \n",
       "1                                    virginamerica plus youve added commercial experience tacky  \n",
       "2                                    virginamerica didnt today must mean need take another trip  \n",
       "3  virginamerica really aggressive blast obnoxious entertainment guest face amp little recourse  \n",
       "4                                                            virginamerica really big bad thing  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"clean_text\"] = df2[\"text\"].apply(cleaning)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "aF3lOouUCluW",
    "outputId": "633444e9-320d-4daa-fca0-099ff1c13e81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP</td>\n",
       "      <td>virginamerica really missed prime opportunity men without hat parody http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn</td>\n",
       "      <td>virginamerica virginmedia im flying fabulous seductive sky u take stress away travel http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I love this graphic. http://t.co/UT5GrRwAaA</td>\n",
       "      <td>virginamerica love graphic http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica this is great news!  America could start flights to Hawaii by end of year http://t.co/r8p2Zy3fe4 via @Pacificbiznews</td>\n",
       "      <td>virginamerica great news america could start flight hawaii end year http via pacificbiznews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Nice RT @VirginAmerica: Vibe with the moodlight from takeoff to touchdown. #MoodlitMonday #ScienceBehindTheExperience http://t.co/Y7O0uNxTQP</td>\n",
       "      <td>nice rt virginamerica vibe moodlight takeoff touchdown moodlitmonday sciencebehindtheexperience http</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "7    neutral   \n",
       "13  positive   \n",
       "21  positive   \n",
       "34  positive   \n",
       "35   neutral   \n",
       "\n",
       "                                                                                                                                            text  \\\n",
       "7                                   @VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP   \n",
       "13  @VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn   \n",
       "21                                                                                    @VirginAmerica I love this graphic. http://t.co/UT5GrRwAaA   \n",
       "34           @VirginAmerica this is great news!  America could start flights to Hawaii by end of year http://t.co/r8p2Zy3fe4 via @Pacificbiznews   \n",
       "35  Nice RT @VirginAmerica: Vibe with the moodlight from takeoff to touchdown. #MoodlitMonday #ScienceBehindTheExperience http://t.co/Y7O0uNxTQP   \n",
       "\n",
       "                                                                                              clean_text  \n",
       "7                              virginamerica really missed prime opportunity men without hat parody http  \n",
       "13             virginamerica virginmedia im flying fabulous seductive sky u take stress away travel http  \n",
       "21                                                                       virginamerica love graphic http  \n",
       "34           virginamerica great news america could start flight hawaii end year http via pacificbiznews  \n",
       "35  nice rt virginamerica vibe moodlight takeoff touchdown moodlitmonday sciencebehindtheexperience http  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URLs\n",
    "df2[df2['clean_text'].str.contains('http')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "nf2j97ZWFu0p",
    "outputId": "c5b34ce7-87fb-4d91-eacc-29015b35b917"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn</td>\n",
       "      <td>virginamerica virginmedia im flying fabulous seductive sky u take stress away travel http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica So excited for my first cross country flight LAX to MCO I've heard nothing but great things about Virgin America. #29DaysToGo</td>\n",
       "      <td>virginamerica excited first cross country flight lax mco ive heard nothing great thing virgin america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica What happened 2 ur vegan food options?! At least say on ur site so i know I won't be able 2 eat anything for next 6 hrs #fail</td>\n",
       "      <td>virginamerica happened ur vegan food option least say ur site know wont able eat anything next hr fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "13  positive   \n",
       "16  positive   \n",
       "26  negative   \n",
       "\n",
       "                                                                                                                                            text  \\\n",
       "13  @VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn   \n",
       "16  @VirginAmerica So excited for my first cross country flight LAX to MCO I've heard nothing but great things about Virgin America. #29DaysToGo   \n",
       "26  @VirginAmerica What happened 2 ur vegan food options?! At least say on ur site so i know I won't be able 2 eat anything for next 6 hrs #fail   \n",
       "\n",
       "                                                                                                clean_text  \n",
       "13               virginamerica virginmedia im flying fabulous seductive sky u take stress away travel http  \n",
       "16   virginamerica excited first cross country flight lax mco ive heard nothing great thing virgin america  \n",
       "26  virginamerica happened ur vegan food option least say ur site know wont able eat anything next hr fail  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tags\n",
    "df2[df2['text'].str.contains('#')].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "4R_8NqmFGlcm",
    "outputId": "2e6333ba-ddb9-434c-d5f2-2c1628da3553"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>virginamerica plus youve added commercial experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>virginamerica didnt today must mean need take another trip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0   neutral   \n",
       "1  positive   \n",
       "2   neutral   \n",
       "\n",
       "                                                                       text  \\\n",
       "0                                       @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2   @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "\n",
       "                                                   clean_text  \n",
       "0                                 virginamerica dhepburn said  \n",
       "1  virginamerica plus youve added commercial experience tacky  \n",
       "2  virginamerica didnt today must mean need take another trip  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mentions\n",
    "df2[df2['text'].str.contains('@')].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "BfCSqNgbQC7Z",
    "outputId": "a0a4bcf3-9ba3-4b86-d0ab-99d9c8d360e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir rocks - @AmericanAir horror</td>\n",
       "      <td>southwestair rock americanair horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@USAirways Do your flight schedules to - from Quintana Roo, Mexico reflect their newly adopted time zone change to EST?</td>\n",
       "      <td>usairways flight schedule quintana roo mexico reflect newly adopted time zone change est</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir briughy me to @ComClassic, #AIF2015 &amp;amp; so much more with the #agcommunity</td>\n",
       "      <td>southwestair briughy comclassic amp much agcommunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13233</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir Trying  to Cancelled Flight fligt 2321 O'Hare to Dallas 12:17pm. High call volume no one answer. Online no confirmation. #thankU</td>\n",
       "      <td>americanair trying cancelled flight fligt ohare dallas high call volume one answer online confirmation thanku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9966</th>\n",
       "      <td>negative</td>\n",
       "      <td>@USAirways I have nothing but issues when I fly w/u what's up w/that?! #travel #vacation #awful</td>\n",
       "      <td>usairways nothing issue fly whats travel vacation awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12792</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir keep up the good work.  Got me to my destination safe and on time today</td>\n",
       "      <td>americanair keep good work got destination safe time today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13024</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir, I've tried no less than 8 times today to get in touch with your service desk beginning at 8:30 EST.  I'm having no luck -help!</td>\n",
       "      <td>americanair ive tried le time today get touch service desk beginning est im luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir I love ya but your bringin me down. An hour Late Flight leaving and now we've been sitting in the runway for 20 min 😥 #fail</td>\n",
       "      <td>southwestair love ya bringin hour late flight leaving weve sitting runway min fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13934</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir yeah, rebooked for tomorrow morning. But extremely disappointed to miss a wedding.</td>\n",
       "      <td>americanair yeah rebooked tomorrow morning extremely disappointed miss wedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir booked our flights this morning. Can't wait to move about the country.</td>\n",
       "      <td>southwestair booked flight morning cant wait move country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  \\\n",
       "5425   negative   \n",
       "9599    neutral   \n",
       "4592    neutral   \n",
       "13233  negative   \n",
       "9966   negative   \n",
       "12792  positive   \n",
       "13024  negative   \n",
       "5780   negative   \n",
       "13934  negative   \n",
       "6055    neutral   \n",
       "\n",
       "                                                                                                                                                text  \\\n",
       "5425                                                                                                       @SouthwestAir rocks - @AmericanAir horror   \n",
       "9599                         @USAirways Do your flight schedules to - from Quintana Roo, Mexico reflect their newly adopted time zone change to EST?   \n",
       "4592                                                      @SouthwestAir briughy me to @ComClassic, #AIF2015 &amp; so much more with the #agcommunity   \n",
       "13233  @AmericanAir Trying  to Cancelled Flight fligt 2321 O'Hare to Dallas 12:17pm. High call volume no one answer. Online no confirmation. #thankU   \n",
       "9966                                                 @USAirways I have nothing but issues when I fly w/u what's up w/that?! #travel #vacation #awful   \n",
       "12792                                                           @AmericanAir keep up the good work.  Got me to my destination safe and on time today   \n",
       "13024   @AmericanAir, I've tried no less than 8 times today to get in touch with your service desk beginning at 8:30 EST.  I'm having no luck -help!   \n",
       "5780       @SouthwestAir I love ya but your bringin me down. An hour Late Flight leaving and now we've been sitting in the runway for 20 min 😥 #fail   \n",
       "13934                                                @AmericanAir yeah, rebooked for tomorrow morning. But extremely disappointed to miss a wedding.   \n",
       "6055                                                            @SouthwestAir booked our flights this morning. Can't wait to move about the country.   \n",
       "\n",
       "                                                                                                          clean_text  \n",
       "5425                                                                            southwestair rock americanair horror  \n",
       "9599                        usairways flight schedule quintana roo mexico reflect newly adopted time zone change est  \n",
       "4592                                                            southwestair briughy comclassic amp much agcommunity  \n",
       "13233  americanair trying cancelled flight fligt ohare dallas high call volume one answer online confirmation thanku  \n",
       "9966                                                         usairways nothing issue fly whats travel vacation awful  \n",
       "12792                                                     americanair keep good work got destination safe time today  \n",
       "13024                               americanair ive tried le time today get touch service desk beginning est im luck  \n",
       "5780                              southwestair love ya bringin hour late flight leaving weve sitting runway min fail  \n",
       "13934                                 americanair yeah rebooked tomorrow morning extremely disappointed miss wedding  \n",
       "6055                                                       southwestair booked flight morning cant wait move country  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "2eGZ03JjERKc"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "#df = pd.read_csv(\"airline_tweets.csv\")\n",
    "\n",
    "df = df[['airline_sentiment','text']]\n",
    "df.rename(columns={'airline_sentiment':'sentiment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0KSFOW1FT-B",
    "outputId": "b7aa098b-7898-4364-d831-a437559ba412"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', 'VirginAmerica', 'What', '@', 'dhepburn', 'said', '.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(df2['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "xymK6fJADf5M"
   },
   "outputs": [],
   "source": [
    "def updated_cleaning(data):\n",
    "\n",
    "    import re\n",
    "    \n",
    "    #1. Removing URLS\n",
    "    data = re.sub(r'http\\S+', '', data)\n",
    "\n",
    "    #2. Removing Tags\n",
    "    data = re.sub(r'#\\w+', '', data)\n",
    "\n",
    "    #3. Removing Mentions\n",
    "    data = re.sub(r'@\\w+', '', data)\n",
    "\n",
    "    #4. Contractions Expension & Tokenize\n",
    "    #text_tokens = word_tokenize(contractions.fix(data.lower())) \n",
    "    text_tokens = word_tokenize(data.replace(\"'\", '').lower())\n",
    "\n",
    "    #5. Removing mentions\n",
    "    tokens_without_mention = [w for w in text_tokens if not w.startswith('@')]\n",
    "    \n",
    "    #6. Remove Puncs\n",
    "    tokens_without_punc = [w for w in tokens_without_mention if w.isalpha()]\n",
    "    \n",
    "    #7. Removing Stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    \n",
    "    #8. lemma\n",
    "    text_cleaned = [WordNetLemmatizer().lemmatize(t) for t in tokens_without_sw]\n",
    "    \n",
    "    #joining\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "W3ApLjV3EhVr"
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"clean_text\"] = df2[\"text\"].apply(updated_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113
    },
    "id": "8Vb2KzdaE5H4",
    "outputId": "98af7186-6bae-4c3b-f7e6-e1c7d9aa812d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, text, clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, text, clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, text, clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['clean_text'].str.contains('http')]\n",
    "df2[df2['clean_text'].str.contains('#')]\n",
    "df2[df2['clean_text'].str.contains('@')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "WivwGmKCCPs9",
    "outputId": "02e1761b-7dc6-4e8e-df85-37f72ce27d63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7875</th>\n",
       "      <td>positive</td>\n",
       "      <td>@JetBlue got it. Thanks</td>\n",
       "      <td>got thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>negative</td>\n",
       "      <td>@USAirways your rude staff said\" I don't care that we are out of market place food you're going on vacation and I have to work\" nice huh</td>\n",
       "      <td>rude staff said dont care market place food youre going vacation work nice huh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@JetBlue  Alright I hope. My JetBlue app is showing a change in my seats and online shows an a320.  Don't want any surprises</td>\n",
       "      <td>alright hope jetblue app showing change seat online show dont want surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>negative</td>\n",
       "      <td>.@united Your airline is again rated the WORST in America so you've got your work cut out for you. It's bc you treat customers like garbage.</td>\n",
       "      <td>airline rated worst america youve got work cut bc treat customer like garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12400</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir 140 characters aren't enough to describe how inconsiderate your employees are</td>\n",
       "      <td>character arent enough describe inconsiderate employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>positive</td>\n",
       "      <td>@USAirways looks like our bag has been rescued. Thanks!</td>\n",
       "      <td>look like bag rescued thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united next flight? Don't think I'll be spending anymore money with you guys ever. It was that bad.</td>\n",
       "      <td>next flight dont think ill spending anymore money guy ever bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir @PHLAirport Will Flight 2155 that arrives at E11 be a penguin plane?</td>\n",
       "      <td>flight arrives penguin plane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>negative</td>\n",
       "      <td>@USAirways @AmericanAir 2hrs Late Flightr finally taking off😂😂😂</td>\n",
       "      <td>late flightr finally taking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 4 passengers after a 2 hour delayed flight left with no hotel at the end of the night @ hou airport. Wtf??!! http://t.co/ZfqMpGXVS6</td>\n",
       "      <td>passenger hour delayed flight left hotel end night hou airport wtf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  \\\n",
       "7875   positive   \n",
       "9764   negative   \n",
       "7664    neutral   \n",
       "2190   negative   \n",
       "12400  negative   \n",
       "9679   positive   \n",
       "3943   negative   \n",
       "4463    neutral   \n",
       "9833   negative   \n",
       "762    negative   \n",
       "\n",
       "                                                                                                                                               text  \\\n",
       "7875                                                                                                                        @JetBlue got it. Thanks   \n",
       "9764       @USAirways your rude staff said\" I don't care that we are out of market place food you're going on vacation and I have to work\" nice huh   \n",
       "7664                   @JetBlue  Alright I hope. My JetBlue app is showing a change in my seats and online shows an a320.  Don't want any surprises   \n",
       "2190   .@united Your airline is again rated the WORST in America so you've got your work cut out for you. It's bc you treat customers like garbage.   \n",
       "12400                                                    @AmericanAir 140 characters aren't enough to describe how inconsiderate your employees are   \n",
       "9679                                                                                        @USAirways looks like our bag has been rescued. Thanks!   \n",
       "3943                                           @united next flight? Don't think I'll be spending anymore money with you guys ever. It was that bad.   \n",
       "4463                                                             @SouthwestAir @PHLAirport Will Flight 2155 that arrives at E11 be a penguin plane?   \n",
       "9833                                                                                @USAirways @AmericanAir 2hrs Late Flightr finally taking off😂😂😂   \n",
       "762     @united 4 passengers after a 2 hour delayed flight left with no hotel at the end of the night @ hou airport. Wtf??!! http://t.co/ZfqMpGXVS6   \n",
       "\n",
       "                                                                           clean_text  \n",
       "7875                                                                       got thanks  \n",
       "9764   rude staff said dont care market place food youre going vacation work nice huh  \n",
       "7664      alright hope jetblue app showing change seat online show dont want surprise  \n",
       "2190    airline rated worst america youve got work cut bc treat customer like garbage  \n",
       "12400                          character arent enough describe inconsiderate employee  \n",
       "9679                                                     look like bag rescued thanks  \n",
       "3943                   next flight dont think ill spending anymore money guy ever bad  \n",
       "4463                                                     flight arrives penguin plane  \n",
       "9833                                                      late flightr finally taking  \n",
       "762                passenger hour delayed flight left hotel end night hou airport wtf  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiySzpXBQC7Z"
   },
   "source": [
    "## CountVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "3vT0WgIsQC7Z"
   },
   "outputs": [],
   "source": [
    "X = df2[[\"clean_text\"]] # as a dataframe\n",
    "y = df2[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "blIHgFYUQC7Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "EjtdilNWQC7a"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 4299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "ii6K_PQ-QC7a",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "70aafe44-938e-46bd-d9fc-59f7a26fff5f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>haha clean plane held overnight hangar sound lovely also dont lie screensand say weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>let seriously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>hello flying first class behind people zone pls pas app dept board class first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9222</th>\n",
       "      <td>worry flight attendant took care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8721</th>\n",
       "      <td>claimed happy way treated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823</th>\n",
       "      <td>yesterday flight wanted chicago sale within point range today isnt way guy still honor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>ive hold hour cc mile arent showing mediocre combo cc amp airline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>yes total hour hold cancelled flightlations one would think would staff decided cx drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>love team running gate la tonight waited delayed flight kept thing entertaining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>bag reference id number thanks looking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11712 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     clean_text\n",
       "3013   haha clean plane held overnight hangar sound lovely also dont lie screensand say weather\n",
       "13868                                                                             let seriously\n",
       "2391             hello flying first class behind people zone pls pas app dept board class first\n",
       "9222                                                           worry flight attendant took care\n",
       "8721                                                                  claimed happy way treated\n",
       "...                                                                                         ...\n",
       "7823     yesterday flight wanted chicago sale within point range today isnt way guy still honor\n",
       "9228                          ive hold hour cc mile arent showing mediocre combo cc amp airline\n",
       "5237   yes total hour hold cancelled flightlations one would think would staff decided cx drive\n",
       "119             love team running gate la tonight waited delayed flight kept thing entertaining\n",
       "2015                                                     bag reference id number thanks looking\n",
       "\n",
       "[11712 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "EkuGrK5dQC7a"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "kG96WszUQC7a"
   },
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer()\n",
    "X_train_count1 = vectorizer1.fit_transform(X_train['clean_text']) # INPUT: should be a list or pd.Series\n",
    "X_test_count1 = vectorizer1.transform(X_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "NTM-lw6XQC7a"
   },
   "outputs": [],
   "source": [
    "#vectorizer1.get_feature_names()[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdcR4-IPQC7a",
    "outputId": "e9b10b96-fa98-445f-e89e-9ad1376101f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7705"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spSMieUwQC7b",
    "outputId": "73c957f7-df2f-4781-c921-2ea1db2b9c50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaaand',\n",
       " 'aadavantage',\n",
       " 'aadv',\n",
       " 'aadvantage',\n",
       " 'aal',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonment',\n",
       " 'abassinet',\n",
       " 'abbreve',\n",
       " 'abc',\n",
       " 'abducted',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abounds']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wS9l71eQC7b"
   },
   "source": [
    "#### min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lBiNHCoQC7b",
    "outputId": "9d29521b-7475-4b42-cb1e-3fc070972d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13244"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/36572221/how-to-find-ngram-frequency-of-a-column-in-a-pandas-dataframe\n",
    "# WHITE BOARD: https://whiteboard.office.com/me/whiteboards/13947786-4746-4a0e-ad23-4c720b363d5c\n",
    "vectorizer2 = CountVectorizer(preprocessor=cleaning, min_df=2, ngram_range=(1,2))\n",
    "X_train_count2 = vectorizer2.fit_transform(X_train['clean_text'])\n",
    "X_test_count2 = vectorizer2.transform(X_test['clean_text'])\n",
    "\n",
    "len(vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCHf9kHLQC7b",
    "outputId": "5bdd0413-13c9-4620-fd37-21aabcb8a150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aa agent',\n",
       " 'aa amp',\n",
       " 'aa customer',\n",
       " 'aa dallas',\n",
       " 'aa dfw',\n",
       " 'aa doesnt',\n",
       " 'aa email',\n",
       " 'aa employee',\n",
       " 'aa family',\n",
       " 'aa flight',\n",
       " 'aa gate',\n",
       " 'aa gold',\n",
       " 'aa help',\n",
       " 'aa mile',\n",
       " 'aa monday',\n",
       " 'aa number',\n",
       " 'aa platinum',\n",
       " 'aa possible',\n",
       " 'aa usair']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FF0HNs5ZQC7b",
    "outputId": "2219a298-60ab-43bd-c1fc-bf226abdccbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "hgGXXR06QC7b",
    "outputId": "45fe98b8-086f-4e38-f04b-14ea25d9793e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa agent</th>\n",
       "      <th>aa amp</th>\n",
       "      <th>aa customer</th>\n",
       "      <th>aa dallas</th>\n",
       "      <th>aa dfw</th>\n",
       "      <th>aa doesnt</th>\n",
       "      <th>aa email</th>\n",
       "      <th>aa employee</th>\n",
       "      <th>aa family</th>\n",
       "      <th>...</th>\n",
       "      <th>yyz</th>\n",
       "      <th>yyz terminal</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero communication</th>\n",
       "      <th>zero entertainment</th>\n",
       "      <th>zero response</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone nine</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11712 rows × 13244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aa agent  aa amp  aa customer  aa dallas  aa dfw  aa doesnt  \\\n",
       "0       0         0       0            0          0       0          0   \n",
       "1       0         0       0            0          0       0          0   \n",
       "2       0         0       0            0          0       0          0   \n",
       "3       0         0       0            0          0       0          0   \n",
       "4       0         0       0            0          0       0          0   \n",
       "...    ..       ...     ...          ...        ...     ...        ...   \n",
       "11707   0         0       0            0          0       0          0   \n",
       "11708   0         0       0            0          0       0          0   \n",
       "11709   0         0       0            0          0       0          0   \n",
       "11710   0         0       0            0          0       0          0   \n",
       "11711   0         0       0            0          0       0          0   \n",
       "\n",
       "       aa email  aa employee  aa family  ...  yyz  yyz terminal  zero  \\\n",
       "0             0            0          0  ...    0             0     0   \n",
       "1             0            0          0  ...    0             0     0   \n",
       "2             0            0          0  ...    0             0     0   \n",
       "3             0            0          0  ...    0             0     0   \n",
       "4             0            0          0  ...    0             0     0   \n",
       "...         ...          ...        ...  ...  ...           ...   ...   \n",
       "11707         0            0          0  ...    0             0     0   \n",
       "11708         0            0          0  ...    0             0     0   \n",
       "11709         0            0          0  ...    0             0     0   \n",
       "11710         0            0          0  ...    0             0     0   \n",
       "11711         0            0          0  ...    0             0     0   \n",
       "\n",
       "       zero communication  zero entertainment  zero response  zone  zone nine  \\\n",
       "0                       0                   0              0     0          0   \n",
       "1                       0                   0              0     0          0   \n",
       "2                       0                   0              0     1          0   \n",
       "3                       0                   0              0     0          0   \n",
       "4                       0                   0              0     0          0   \n",
       "...                   ...                 ...            ...   ...        ...   \n",
       "11707                   0                   0              0     0          0   \n",
       "11708                   0                   0              0     0          0   \n",
       "11709                   0                   0              0     0          0   \n",
       "11710                   0                   0              0     0          0   \n",
       "11711                   0                   0              0     0          0   \n",
       "\n",
       "       zoom  zurich  \n",
       "0         0       0  \n",
       "1         0       0  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "...     ...     ...  \n",
       "11707     0       0  \n",
       "11708     0       0  \n",
       "11709     0       0  \n",
       "11710     0       0  \n",
       "11711     0       0  \n",
       "\n",
       "[11712 rows x 13244 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(X_train_count2.toarray(), columns = vectorizer2.get_feature_names())\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5Nanul9QC7c",
    "outputId": "7ecbaf2f-2f08-4e2c-968b-6b6143290538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before min_df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('aa', 168),\n",
       " ('aaaand', 1),\n",
       " ('aadavantage', 1),\n",
       " ('aadv', 2),\n",
       " ('aadvantage', 9),\n",
       " ('aal', 1),\n",
       " ('aaron', 1),\n",
       " ('ab', 1),\n",
       " ('aback', 1),\n",
       " ('abandon', 1),\n",
       " ('abandoned', 1),\n",
       " ('abandonment', 1),\n",
       " ('abassinet', 1),\n",
       " ('abbreve', 1),\n",
       " ('abc', 6),\n",
       " ('abducted', 1),\n",
       " ('ability', 4),\n",
       " ('able', 93),\n",
       " ('aboard', 3),\n",
       " ('abounds', 1)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After min_df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('aa', 168),\n",
       " ('aa agent', 3),\n",
       " ('aa amp', 4),\n",
       " ('aa customer', 4),\n",
       " ('aa dallas', 2),\n",
       " ('aa dfw', 2),\n",
       " ('aa doesnt', 2),\n",
       " ('aa email', 2),\n",
       " ('aa employee', 4),\n",
       " ('aa family', 2),\n",
       " ('aa flight', 5),\n",
       " ('aa gate', 2),\n",
       " ('aa gold', 2),\n",
       " ('aa help', 3),\n",
       " ('aa mile', 2),\n",
       " ('aa monday', 2),\n",
       " ('aa number', 2),\n",
       " ('aa platinum', 2),\n",
       " ('aa possible', 2),\n",
       " ('aa usair', 2)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP 20 TOKENS\n",
    "print('Before min_df')\n",
    "list(zip(vectorizer1.get_feature_names(), X_train_count1.toarray().sum(axis=0)))[:20]\n",
    "print('\\n')\n",
    "print('After min_df')\n",
    "list(zip(vectorizer2.get_feature_names(), X_train_count2.toarray().sum(axis=0)))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9z4VzD1mQC7c",
    "outputId": "2ee397ea-fe75-45f8-e3fe-c87e9139bab6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    didnt today must mean need take another trip\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KVi7vfzQC7c"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Y2lePoRQC7c"
   },
   "source": [
    "🔑 : sklearn TD-IDF\n",
    "https://towardsdatascience.com/how-sklearns-tf-idf-is-different-from-the-standard-tf-idf-275fa582e73d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Oo2j3kjzQC7c"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "euxCrAL-QC7c"
   },
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "X_train_tf_idf = tf_idf_vectorizer.fit_transform(X_train['clean_text'])\n",
    "X_test_tf_idf = tf_idf_vectorizer.transform(X_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byiZxyK5QC7c",
    "outputId": "a34394d8-3518-41d9-ec9d-d81a26f5f6a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaaand',\n",
       " 'aadavantage',\n",
       " 'aadv',\n",
       " 'aadvantage',\n",
       " 'aal',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonment',\n",
       " 'abassinet',\n",
       " 'abbreve',\n",
       " 'abc',\n",
       " 'abducted',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abounds',\n",
       " 'abq',\n",
       " 'abroad',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer.get_feature_names()[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FfCRDWxQC7d",
    "outputId": "dd16ddbf-33cf-4fd1-f014-b7ac20be8dc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "SJY0L5kYQC7d",
    "outputId": "9431c05c-7c81-4f1a-8b86-77ab5d947132"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aal</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zambia</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 7705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaand  aadavantage  aadv  aadvantage  aal  aaron   ab  aback  \\\n",
       "0  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "1  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "2  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "3  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "4  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "5  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "6  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "7  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "8  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "9  0.0     0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0   \n",
       "\n",
       "   abandon  ...  yyz  zabsonre  zambia  zero  zip  zipper      zone  zoom  \\\n",
       "0      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "1      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "2      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.312678   0.0   \n",
       "3      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "4      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "5      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "6      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "7      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "8      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "9      0.0  ...  0.0       0.0     0.0   0.0  0.0     0.0  0.000000   0.0   \n",
       "\n",
       "   zukes  zurich  \n",
       "0    0.0     0.0  \n",
       "1    0.0     0.0  \n",
       "2    0.0     0.0  \n",
       "3    0.0     0.0  \n",
       "4    0.0     0.0  \n",
       "5    0.0     0.0  \n",
       "6    0.0     0.0  \n",
       "7    0.0     0.0  \n",
       "8    0.0     0.0  \n",
       "9    0.0     0.0  \n",
       "\n",
       "[10 rows x 7705 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_tf_idf.toarray(), columns = tf_idf_vectorizer.get_feature_names())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foZsEUCXQC7d",
    "outputId": "2f3c55c0-e844-4e3e-9a9e-76564ebbcbb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    seriously would pay flight seat didnt playing really bad thing flying va\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bE5b20ifQC7d",
    "outputId": "c422ad3c-baec-48c3-d45d-9702ddf2d6a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seriously          0.774457\n",
       "let                0.632627\n",
       "pregame            0.000000\n",
       "preregistration    0.000000\n",
       "prepares           0.000000\n",
       "prepared           0.000000\n",
       "prepare            0.000000\n",
       "preparation        0.000000\n",
       "preoccupied        0.000000\n",
       "premium            0.000000\n",
       "premiere           0.000000\n",
       "premier            0.000000\n",
       "prem               0.000000\n",
       "pregnant           0.000000\n",
       "preggo             0.000000\n",
       "prefference        0.000000\n",
       "present            0.000000\n",
       "preferred          0.000000\n",
       "preference         0.000000\n",
       "preferably         0.000000\n",
       "prefer             0.000000\n",
       "pref               0.000000\n",
       "preemptive         0.000000\n",
       "predictive         0.000000\n",
       "predicted          0.000000\n",
       "predictable        0.000000\n",
       "predict            0.000000\n",
       "precludes          0.000000\n",
       "precipitation      0.000000\n",
       "prescreen          0.000000\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_tf_idf.toarray(), columns = tf_idf_vectorizer.get_feature_names()).loc[1].sort_values(ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "itzf8WY0QC7d",
    "outputId": "063940b5-e56e-479c-d094-e63bf1fa5260"
   },
   "outputs": [],
   "source": [
    "df2[df2['clean_text'].str.contains('let')][['sentiment', 'clean_text']]['sentiment'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "QMlm3JfTQC7d",
    "outputId": "699e4ca3-546a-4a6d-8055-b8638b0bebc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>neutral</td>\n",
       "      <td>new marketing song let u know think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>neutral</td>\n",
       "      <td>emailed customer service team let know need tracking number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>negative</td>\n",
       "      <td>let scanned passenger leave plane told someone remove bag class bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>negative</td>\n",
       "      <td>trying book flight guy website wont let lose business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>negative</td>\n",
       "      <td>mobile site broken show number point wont let checkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14364</th>\n",
       "      <td>negative</td>\n",
       "      <td>im trying call book reward ticket one world partner automated system wont let talk great job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>negative</td>\n",
       "      <td>let crew member know every time happens time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14429</th>\n",
       "      <td>negative</td>\n",
       "      <td>reservation system wont even let u leave phone way fix rebooked wrong day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14528</th>\n",
       "      <td>negative</td>\n",
       "      <td>let employee treat loyal customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14578</th>\n",
       "      <td>negative</td>\n",
       "      <td>call center wont let wait hold would happily seriously supposed keep calling great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  \\\n",
       "59      neutral   \n",
       "71      neutral   \n",
       "97     negative   \n",
       "191    negative   \n",
       "216    negative   \n",
       "...         ...   \n",
       "14364  negative   \n",
       "14375  negative   \n",
       "14429  negative   \n",
       "14528  negative   \n",
       "14578  negative   \n",
       "\n",
       "                                                                                         clean_text  \n",
       "59                                                              new marketing song let u know think  \n",
       "71                                      emailed customer service team let know need tracking number  \n",
       "97                              let scanned passenger leave plane told someone remove bag class bin  \n",
       "191                                           trying book flight guy website wont let lose business  \n",
       "216                                           mobile site broken show number point wont let checkin  \n",
       "...                                                                                             ...  \n",
       "14364  im trying call book reward ticket one world partner automated system wont let talk great job  \n",
       "14375                                                  let crew member know every time happens time  \n",
       "14429                     reservation system wont even let u leave phone way fix rebooked wrong day  \n",
       "14528                                                             let employee treat loyal customer  \n",
       "14578            call center wont let wait hold would happily seriously supposed keep calling great  \n",
       "\n",
       "[266 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['clean_text'].str.contains('let ')][['sentiment', 'clean_text']]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-1 (Data Cleaning-Vectorization)(ENG)-Nov 17 2021-S.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
